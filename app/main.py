import requests
from fastapi import FastAPI
from bs4 import BeautifulSoup
import html
from dotenv import load_dotenv
import os
import openai

# .env í™˜ê²½ë³€ìˆ˜ ë¡œë“œ
load_dotenv()
NAVER_CLIENT_ID = os.getenv("NAVER_CLIENT_ID")
NAVER_CLIENT_SECRET = os.getenv("NAVER_CLIENT_SECRET")
OPENAI_API_KEY = os.getenv("OPENAI_API_KEY")

# OpenAI í´ë¼ì´ì–¸íŠ¸
client = openai.OpenAI(api_key=OPENAI_API_KEY)

# ğŸ‘‰ ë‰´ìŠ¤ ìš”ì•½ ê¸°ëŠ¥ on/off í† ê¸€
ENABLE_NEWS_SUMMARY = False  # Trueë¡œ ë³€ê²½í•˜ë©´ ìš”ì•½ ê¸°ëŠ¥ í™œì„±í™”

app = FastAPI()

@app.get("/")
def read_root():
    return {"message": "Hello, FastAPI is running!"}

@app.get("/price")
def get_price():
    url = "https://api.upbit.com/v1/ticker?markets=KRW-BTC"
    response = requests.get(url)
    data = response.json()
    return {
        "price": data[0]["trade_price"],
        "high": data[0]["high_price"],
        "low": data[0]["low_price"],
        "change_rate": data[0]["signed_change_rate"]
    }

@app.get("/news")
def get_news():
    return get_naver_news_api()

@app.get("/report")
def get_report():
    news_data = get_naver_news_api()
    summarized_news = []
    all_summaries = []

    for item in news_data:
        content = get_article_content(item['url'])

        if ENABLE_NEWS_SUMMARY:
            if not content or len(content) < 100:
                summary = "ê¸°ì‚¬ ë³¸ë¬¸ í¬ë¡¤ë§ ì‹¤íŒ¨: ë‚´ìš© ë¶€ì¡±"
            else:
                summary = summarize_text(content)
        else:
            summary = "ìš”ì•½ ê¸°ëŠ¥ ë¹„í™œì„±í™”ë¨"

        all_summaries.append(summary)
        summarized_news.append({
            "title": item['title'],
            "url": item['url'],
            "summary": summary
        })

    combined_summary = "\n".join(all_summaries)

    investment_comment = summarize_text(
        f"""
        ë‹¹ì‹ ì€ ë¹„íŠ¸ì½”ì¸ ì „ë¬¸ ë¦¬ì„œì¹˜ì„¼í„° ì†Œì† ì• ë„ë¦¬ìŠ¤íŠ¸ì…ë‹ˆë‹¤.
        ë‹¤ìŒì€ ìµœê·¼ ë¹„íŠ¸ì½”ì¸ ê´€ë ¨ ë‰´ìŠ¤ ìš”ì•½ì…ë‹ˆë‹¤:

        {combined_summary}

        ì´ ìš”ì•½ì„ ê¸°ë°˜ìœ¼ë¡œ, ë‹¤ìŒ ì¡°ê±´ì„ ëª¨ë‘ ë§Œì¡±í•˜ëŠ” íˆ¬ì ì˜ê²¬ì„œë¥¼ ì‘ì„±í•´ ì£¼ì„¸ìš”:
        1. ì‹¤ì œ ì¦ê¶Œì‚¬, ë¦¬ì„œì¹˜ ê¸°ê´€ì—ì„œ ë°œí–‰í•˜ëŠ” íˆ¬ì ë³´ê³ ì„œ í˜•ì‹        
        2. 3ë¬¸ë‹¨ ì •ë„        
        3. ë¬¸ì²´: ì „ë¬¸ì ì´ê³  ê°ê´€ì , ë¶„ì„ì ì¸ ë¬¸ì²´
        4. ë‚´ìš©:
           - í˜„ì¬ ê°€ê²© ë™í–¥ ìš”ì•½
           - ì£¼ìš” ì´ìŠˆ ë° ì´ë²¤íŠ¸
           - ì‹œì¥ ë™í–¥ ë¶„ì„
           - ë¦¬ìŠ¤í¬ ìš”ì¸
           - ì¢…í•©ì ì¸ íˆ¬ìì˜ê²¬
        5. í•„ìš”í•˜ë‹¤ë©´ ìµœê·¼ ì•Œë ¤ì§„ ì‹œì¥ ì •ë³´ë‚˜ ë°ì´í„°ëŠ” ì¸í„°ë„· ê²€ìƒ‰ì„ í†µí•´ ë³´ì™„í•œ ë“¯í•œ ë‚´ìš© í¬í•¨
        6. ë‰´ìŠ¤ ë‚´ìš© ë‹¨ìˆœ ìš”ì•½ì´ ì•„ë‹ˆë¼ â†’ ë‰´ìŠ¤ ê¸°ë°˜ í•´ì„/ë¶„ì„ í¬í•¨        
        7. ê²°ê³¼ëŠ” ë§ˆí¬ë‹¤ìš´(Markdown) í˜•ì‹ìœ¼ë¡œ ì‘ì„±
        """
    )

    price_data = get_price()

    return {
        "price": price_data,
        "news": summarized_news,
        "investment_report": investment_comment
    }

def get_naver_news_api():
    query = "ë¹„íŠ¸ì½”ì¸"
    url = f"https://openapi.naver.com/v1/search/news.json?query={query}&display=100"
    headers = {
        "X-Naver-Client-Id": NAVER_CLIENT_ID,
        "X-Naver-Client-Secret": NAVER_CLIENT_SECRET
    }
    response = requests.get(url, headers=headers)
    if response.status_code == 200:
        data = response.json()
        news_list = []
        for item in data['items']:
            if "n.news.naver.com" in item['link']:
                title_unescaped = html.unescape(item['title'])
                title_clean = BeautifulSoup(title_unescaped, "html.parser").get_text()
                news_list.append({
                    "title": title_clean,
                    "url": item['link']
                })
                if len(news_list) == 10:
                    break
        return news_list
    else:
        print(f"API ìš”ì²­ ì‹¤íŒ¨: {response.status_code}")
        return []

def get_article_content(url):
    headers = {"User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64)"}
    response = requests.get(url, headers=headers)
    soup = BeautifulSoup(response.text, 'html.parser')
    article_body = (
        soup.select_one('div#newsct_article') or
        soup.select_one('div#articeBody') or
        soup.select_one('div#articleBodyContents')
    )
    if article_body:
        return article_body.get_text(strip=True)
    else:
        return ""

def summarize_text(text):
    if not text:    
        return "ë³¸ë¬¸ ì—†ìŒ"

    response = client.chat.completions.create(
        model="gpt-3.5-turbo",
        messages=[
            {"role": "system", "content": "ë‹¤ìŒ ë‰´ìŠ¤ ê¸°ì‚¬ë¥¼ í•œ ë¬¸ë‹¨ìœ¼ë¡œ ìš”ì•½í•´ì¤˜."},
            {"role": "user", "content": text}
        ],
        max_tokens=1000
    )
    return response.choices[0].message.content.strip()

@app.get("/ohlcv")
def get_ohlcv_endpoint():
    return get_bitcoin_ohlcv()

def get_bitcoin_ohlcv():
    url = "https://api.upbit.com/v1/candles/days"
    params = {"market": "KRW-BTC", "count": 7}
    response = requests.get(url, params=params)
    if response.status_code == 200:
        return response.json()
    else:
        return []